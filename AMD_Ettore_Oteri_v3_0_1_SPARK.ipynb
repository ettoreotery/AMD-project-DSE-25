{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVn1bNtrrb/DYaAFZtcZ09",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ettoreotery/AMD-project-DSE-25/blob/main/AMD_Ettore_Oteri_v3_0_1_SPARK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KpkXBXXNWCc",
        "outputId": "7ac320d9-bbfb-464e-d19d-ab34db47a6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"ettoreoteri\"\n",
        "os.environ['KAGGLE_KEY'] = \"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews\n",
        "!unzip -q \"*.zip\" -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv(\"Books_rating.csv\")\n",
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "DoqZQoqGNhdv",
        "outputId": "758fea0a-dcbc-4e35-9f40-380a696dbd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id                           Title  Price         User_id  \\\n",
              "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
              "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
              "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
              "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
              "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
              "\n",
              "                          profileName review/helpfulness  review/score  \\\n",
              "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
              "1                       Kevin Killian              10/10           5.0   \n",
              "2                        John Granger              10/11           5.0   \n",
              "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
              "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
              "\n",
              "   review/time                                   review/summary  \\\n",
              "0    940636800           Nice collection of Julie Strain images   \n",
              "1   1095724800                                Really Enjoyed It   \n",
              "2   1078790400  Essential for every personal and Public Library   \n",
              "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
              "4   1107993600                           Good academic overview   \n",
              "\n",
              "                                         review/text  \n",
              "0  This is only for Julie Strain fans. It's a col...  \n",
              "1  I don't care much for Dr. Seuss but after read...  \n",
              "2  If people become the books they read and if \"t...  \n",
              "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
              "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe69aeb4-761c-4348-821d-57f14ee1a447\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Price</th>\n",
              "      <th>User_id</th>\n",
              "      <th>profileName</th>\n",
              "      <th>review/helpfulness</th>\n",
              "      <th>review/score</th>\n",
              "      <th>review/time</th>\n",
              "      <th>review/summary</th>\n",
              "      <th>review/text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1882931173</td>\n",
              "      <td>Its Only Art If Its Well Hung!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AVCGYZL8FQQTD</td>\n",
              "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
              "      <td>7/7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>940636800</td>\n",
              "      <td>Nice collection of Julie Strain images</td>\n",
              "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A30TK6U7DNS82R</td>\n",
              "      <td>Kevin Killian</td>\n",
              "      <td>10/10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1095724800</td>\n",
              "      <td>Really Enjoyed It</td>\n",
              "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A3UH4UZ4RSVO82</td>\n",
              "      <td>John Granger</td>\n",
              "      <td>10/11</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1078790400</td>\n",
              "      <td>Essential for every personal and Public Library</td>\n",
              "      <td>If people become the books they read and if \"t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A2MVUWT453QH61</td>\n",
              "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
              "      <td>7/7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1090713600</td>\n",
              "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
              "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A22X4XUPKF66MR</td>\n",
              "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
              "      <td>3/3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1107993600</td>\n",
              "      <td>Good academic overview</td>\n",
              "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe69aeb4-761c-4348-821d-57f14ee1a447')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe69aeb4-761c-4348-821d-57f14ee1a447 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe69aeb4-761c-4348-821d-57f14ee1a447');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a09bc55b-ccc3-4784-be96-b5b60493a07f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a09bc55b-ccc3-4784-be96-b5b60493a07f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a09bc55b-ccc3-4784-be96-b5b60493a07f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This dataset contains {df1.shape[0]} rows and {df1.shape[1]} columns.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b-s_-9HNqrY",
        "outputId": "d3e1ae94-a417-4759-dc93-3df45e663c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset contains 3000000 rows and 10 columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark nltk\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from itertools import combinations\n",
        "import random\n",
        "\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS8ek3Z6NvBx",
        "outputId": "860ee82d-6527-4184-d87b-bf7d2e5f093d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark configuration\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BookReviewsJaccard\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.executor.memory\", \"8g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "SAux4ubZN3E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsampling\n",
        "SAMPLE_SIZE = 1000  # Sample size when subsampling\n",
        "SEED = 42\n",
        "USE_FULL_DATA = False  # Set to True to disable subsampling"
      ],
      "metadata": {
        "id": "qPWg8jU5N71B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing with error handling\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    try:\n",
        "        if not isinstance(text, str):\n",
        "            return []\n",
        "        text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "        tokens = word_tokenize(text)\n",
        "        return [lemmatizer.lemmatize(w) for w in tokens\n",
        "               if w not in stop_words and len(w) > 2]\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "# Load function to extract only review texts\n",
        "def load_review_texts():\n",
        "    # Read the review/text column\n",
        "    lines = sc.textFile(\"Books_rating.csv\")\n",
        "    header = lines.first()\n",
        "\n",
        "    # Extract only the review text column\n",
        "    review_lines = lines.filter(lambda line: line != header) \\\n",
        "                      .map(lambda line: line.split('\"')[-2] if '\"' in line else line.split(',')[-1])\n",
        "\n",
        "    # Sampling logic\n",
        "    sampled_reviews = review_lines.filter(lambda x: len(x) > 10).collect() if USE_FULL_DATA else review_lines.filter(lambda x: len(x) > 10).takeSample(False, SAMPLE_SIZE, SEED)\n",
        "\n",
        "    # Process sampled reviews\n",
        "    processed_reviews = []\n",
        "    for text in sampled_reviews:\n",
        "        processed = preprocess_text(text)\n",
        "        if len(processed) >= 5:  # Only keep reviews with enough tokens\n",
        "            processed_reviews.append((text, processed))\n",
        "\n",
        "    return sc.parallelize(processed_reviews, numSlices=8)\n",
        "\n",
        "# Process data\n",
        "reviews_rdd = load_review_texts().cache()\n",
        "\n",
        "print(f\"Sample size loaded: {reviews_rdd.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNPjgz3FOBoD",
        "outputId": "ccb42048-b2ba-4a9b-c89c-b84500fb074f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample size loaded: 969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarity calculation\n",
        "def jaccard_similarity(pair):\n",
        "    set1 = set(pair[0][1])  # processed tokens from first review\n",
        "    set2 = set(pair[1][1])  # processed tokens from second review\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "    return (pair[0][0], pair[1][0], intersection / union if union else 0.0, set1 & set2)\n",
        "\n",
        "# Generate and process pairs\n",
        "def process_pairs(rdd):\n",
        "    return rdd.zipWithIndex() \\\n",
        "            .map(lambda x: (x[1]//1000, x[0])) \\\n",
        "            .groupByKey() \\\n",
        "            .flatMap(lambda x: [(v1, v2) for v1, v2 in combinations(list(x[1]), 2)]) \\\n",
        "            .filter(lambda x: x[0] != x[1]) \\\n",
        "            .map(jaccard_similarity) \\\n",
        "            .filter(lambda x: x[2] > 0)\n",
        "\n",
        "# Get top pairs\n",
        "top_pairs = process_pairs(reviews_rdd).takeOrdered(20, key=lambda x: -x[2])\n",
        "\n",
        "# Print results\n",
        "print(\"\\nTOP 20 MOST SIMILAR PAIRS:\")\n",
        "for idx, (text1, text2, sim, common_tokens) in enumerate(top_pairs, 1):\n",
        "    print(f\"\\n#{idx}: Similarity = {sim:.4f}\")\n",
        "    print(\"\\nReview 1:\")\n",
        "    print(text1)\n",
        "    print(\"\\nReview 2:\")\n",
        "    print(text2)\n",
        "    print(f\"\\nCommon tokens ({len(common_tokens)}): {common_tokens}\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFQxUY-1OE8f",
        "outputId": "8dcd5140-71e3-444d-92c8-17f36e8dde09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TOP 20 MOST SIMILAR PAIRS:\n",
            "\n",
            "#1: Similarity = 0.2609\n",
            "\n",
            "Review 1:\n",
            "This was pretty good overall. Nothing particulary ground-shaking and I've read a lot of these things in other books too. Still, it was well presented and helpful.Recommended.\n",
            "\n",
            "Review 2:\n",
            "It's a lot more fun to read to your kid if the book has humour and imagination like most of these beginner books do.Not the best but still pretty good.\n",
            "\n",
            "Common tokens (6): {'pretty', 'good', 'lot', 'book', 'still', 'read'}\n",
            "====================================================================================================\n",
            "\n",
            "#2: Similarity = 0.2500\n",
            "\n",
            "Review 1:\n",
            "I read Blackout and All Clear b/f this novel. Blackout and All Clear were great. Doomsday Book is good but not nearly as interesting as the other two.\n",
            "\n",
            "Review 2:\n",
            "I just read it to my brother and he was happy and thought it was a great book. I finished the book and thought that it was a pretty good book.\n",
            "\n",
            "Common tokens (4): {'great', 'read', 'book', 'good'}\n",
            "====================================================================================================\n",
            "\n",
            "#3: Similarity = 0.2500\n",
            "\n",
            "Review 1:\n",
            "The book arrived within the time range allotted for shipping, and in great condition. Would not have any problem doing business with this seller in future.\n",
            "\n",
            "Review 2:\n",
            "Guess I didn't review this in good time. Book was in great condition and seller was prompt in shipping. BTW if you get a chance to read this, it's worth your while!\n",
            "\n",
            "Common tokens (6): {'time', 'great', 'book', 'condition', 'shipping', 'seller'}\n",
            "====================================================================================================\n",
            "\n",
            "#4: Similarity = 0.2500\n",
            "\n",
            "Review 1:\n",
            "This book is absolutely the best of Grisham. And I've read them all! The ending has a twist like no other !\n",
            "\n",
            "Review 2:\n",
            "Much more information in this book than in any other book I've read on the subject\n",
            "\n",
            "Common tokens (3): {'book', 'read', 'ive'}\n",
            "====================================================================================================\n",
            "\n",
            "#5: Similarity = 0.2353\n",
            "\n",
            "Review 1:\n",
            "This book is absolutely the best of Grisham. And I've read them all! The ending has a twist like no other !\n",
            "\n",
            "Review 2:\n",
            "I just wanna say that this book IS THE BEST OF ALL THE CLAN NOVELS I'VE READ SO FAR... SIMPLY AMAZING, bye\n",
            "\n",
            "Common tokens (4): {'book', 'read', 'ive', 'best'}\n",
            "====================================================================================================\n",
            "\n",
            "#6: Similarity = 0.2353\n",
            "\n",
            "Review 1:\n",
            "Interesting book well written, good details and good pictures, an insperation to those who seek some good ideas in looking as space saving ideas.\n",
            "\n",
            "Review 2:\n",
            "What a great book. Well written, straight forward, good examples.\n",
            "\n",
            "Common tokens (4): {'well', 'book', 'good', 'written'}\n",
            "====================================================================================================\n",
            "\n",
            "#7: Similarity = 0.2326\n",
            "\n",
            "Review 1:\n",
            "In a nutshell: beautifully written and the characterizations were perfect. The author did a perfect job with both. You knew the characters from what they said and how they said it. You saw the surroundings from the clear descriptions. I read many books, and I must recommend it to people who love both a good story AND great writing. It had both, many books do not. A classic, good book.\n",
            "\n",
            "Review 2:\n",
            "Had this book on my shelf for quite a while before finally deciding to tackle it. Wow! Why did I wait? This book is beautifully written. The characters are real and the story line is timely. What a great book. It is in my top 10 of all time favorites. The author is genius. I love to read books with great writing and this definately fits the bill.\n",
            "\n",
            "Common tokens (10): {'writing', 'great', 'written', 'story', 'love', 'author', 'book', 'character', 'beautifully', 'read'}\n",
            "====================================================================================================\n",
            "\n",
            "#8: Similarity = 0.2273\n",
            "\n",
            "Review 1:\n",
            "This is the first book I have read by this author, and found it very entertaining. Will look for other books in this series.\n",
            "\n",
            "Review 2:\n",
            "I really enjoyed reading this book. Can't wait to read the remaining books in the series. Great Christian Fiction. This is my first ebook and look forward to finding more free books in this category.\n",
            "\n",
            "Common tokens (5): {'read', 'first', 'book', 'series', 'look'}\n",
            "====================================================================================================\n",
            "\n",
            "#9: Similarity = 0.2258\n",
            "\n",
            "Review 1:\n",
            "This is a very good book, the main male and female characters are engaging and likable. But it didn't quite have the mythic weight of Memory and Dream to me...some of the characters seemed like they belonged in a second-rate detective novel, not in this book. But still well worth reading.\n",
            "\n",
            "Review 2:\n",
            "I thought this book was pretty good.Love the character of Sam but I didn't quite like Deanie.Somehow she infuriates me but this book is worth reading.\n",
            "\n",
            "Common tokens (7): {'quite', 'didnt', 'book', 'character', 'like', 'reading', 'worth'}\n",
            "====================================================================================================\n",
            "\n",
            "#10: Similarity = 0.2174\n",
            "\n",
            "Review 1:\n",
            "A must read. This book is great. High school students should all be required to read it.\n",
            "\n",
            "Review 2:\n",
            "I've read this book 3 times. First in high school, then in college, and most recently a week ago. It's great everytime I read it. Takes place early on when the standard issue weapon was the M-14.\n",
            "\n",
            "Common tokens (5): {'high', 'great', 'book', 'read', 'school'}\n",
            "====================================================================================================\n",
            "\n",
            "#11: Similarity = 0.2143\n",
            "\n",
            "Review 1:\n",
            "I highly recommend Black Beauty to all readers. It reminded me of the book I had when I was a child.\n",
            "\n",
            "Review 2:\n",
            "I ordered this book for class and it is wonderful. I highly recommend it for those interested in dream work.\n",
            "\n",
            "Common tokens (3): {'recommend', 'highly', 'book'}\n",
            "====================================================================================================\n",
            "\n",
            "#12: Similarity = 0.2143\n",
            "\n",
            "Review 1:\n",
            "A must read. This book is great. High school students should all be required to read it.\n",
            "\n",
            "Review 2:\n",
            "I just read it to my brother and he was happy and thought it was a great book. I finished the book and thought that it was a pretty good book.\n",
            "\n",
            "Common tokens (3): {'great', 'book', 'read'}\n",
            "====================================================================================================\n",
            "\n",
            "#13: Similarity = 0.2143\n",
            "\n",
            "Review 1:\n",
            "A must read. This book is great. High school students should all be required to read it.\n",
            "\n",
            "Review 2:\n",
            "the book was a great purchase, a classic....I never got to read as a child and now i get to.\n",
            "\n",
            "Common tokens (3): {'great', 'book', 'read'}\n",
            "====================================================================================================\n",
            "\n",
            "#14: Similarity = 0.2143\n",
            "\n",
            "Review 1:\n",
            "I just read it to my brother and he was happy and thought it was a great book. I finished the book and thought that it was a pretty good book.\n",
            "\n",
            "Review 2:\n",
            "It was a five star from beginning to end it. Was as good has anyOf her other books I have read\n",
            "\n",
            "Common tokens (3): {'read', 'book', 'good'}\n",
            "====================================================================================================\n",
            "\n",
            "#15: Similarity = 0.2143\n",
            "\n",
            "Review 1:\n",
            "I just read it to my brother and he was happy and thought it was a great book. I finished the book and thought that it was a pretty good book.\n",
            "\n",
            "Review 2:\n",
            "What a great book. Well written, straight forward, good examples.\n",
            "\n",
            "Common tokens (3): {'great', 'book', 'good'}\n",
            "====================================================================================================\n",
            "\n",
            "#16: Similarity = 0.2121\n",
            "\n",
            "Review 1:\n",
            "I thought that the book was very interesting. It was about the only book that I was able to read and like in English class. I thought that the ending was unexpecting, and I loved it for that . I love surprises. I really recommend this book to those of you that are thinking of reading it. I really liked it. I hope you will too.\n",
            "\n",
            "Review 2:\n",
            "this is a great book! i thought it was very interesting and it had a very unfortunate ending. if you like books with a happy ending, you will not like this book. i thought it was really good but it was boring at some times. all the information in the boring parts are necessary to understand the end. if you like books that are about things that go from bad to worse, you will love this book!\n",
            "\n",
            "Common tokens (7): {'really', 'love', 'book', 'like', 'ending', 'thought', 'interesting'}\n",
            "====================================================================================================\n",
            "\n",
            "#17: Similarity = 0.2105\n",
            "\n",
            "Review 1:\n",
            "This book is absolutely the best of Grisham. And I've read them all! The ending has a twist like no other !\n",
            "\n",
            "Review 2:\n",
            "It's a lot more fun to read to your kid if the book has humour and imagination like most of these beginner books do.Not the best but still pretty good.\n",
            "\n",
            "Common tokens (4): {'like', 'book', 'read', 'best'}\n",
            "====================================================================================================\n",
            "\n",
            "#18: Similarity = 0.2105\n",
            "\n",
            "Review 1:\n",
            "I just read it to my brother and he was happy and thought it was a great book. I finished the book and thought that it was a pretty good book.\n",
            "\n",
            "Review 2:\n",
            "It's a lot more fun to read to your kid if the book has humour and imagination like most of these beginner books do.Not the best but still pretty good.\n",
            "\n",
            "Common tokens (4): {'read', 'book', 'good', 'pretty'}\n",
            "====================================================================================================\n",
            "\n",
            "#19: Similarity = 0.2105\n",
            "\n",
            "Review 1:\n",
            "I found contradictory information in this self-help book, and the author was not helpful when I pointed out the discrepancies. Accordingly, I would not recomment this book to anyone.\n",
            "\n",
            "Review 2:\n",
            "Just a wonderful book would suggest to all to read.This book is helpful to anyone struggling. It is a good read.\n",
            "\n",
            "Common tokens (4): {'anyone', 'book', 'helpful', 'would'}\n",
            "====================================================================================================\n",
            "\n",
            "#20: Similarity = 0.2000\n",
            "\n",
            "Review 1:\n",
            "I read lots of books. This is a book though not my favorite I enjoy. I recomend this book.\n",
            "\n",
            "Review 2:\n",
            "It was a good read and gave me a lot to think about.\n",
            "\n",
            "Common tokens (2): {'lot', 'read'}\n",
            "====================================================================================================\n"
          ]
        }
      ]
    }
  ]
}